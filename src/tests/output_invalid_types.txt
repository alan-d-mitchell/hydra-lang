=== HYDRA LANGUAGE COMPILER ===
Compiling file: src/tests/invalid_types.hydra
File size: 1006 bytes

=== PHASE 1: LEXICAL ANALYSIS (TOKENIZING) ===
✅ Tokenization successful!
Tokens found: 170

Debug: All tokens:
    0: Token { token_type: Global, lexeme: "global", line: 1, column: 1 }
    1: Token { token_type: Const, lexeme: "const", line: 1, column: 8 }
    2: Token { token_type: StringType, lexeme: "string", line: 1, column: 14 }
    3: Token { token_type: Identifier("NUMBER"), lexeme: "NUMBER", line: 1, column: 21 }
    4: Token { token_type: Assign, lexeme: "=", line: 1, column: 28 }
    5: Token { token_type: IntLiteral(42), lexeme: "42", line: 1, column: 30 }
    6: Token { token_type: Semicolon, lexeme: ";", line: 1, column: 32 }
    7: Token { token_type: Newline, lexeme: "\n", line: 1, column: 58 }
    8: Token { token_type: Newline, lexeme: "\n", line: 2, column: 1 }
    9: Token { token_type: Func, lexeme: "func", line: 3, column: 0 }
   10: Token { token_type: Identifier("badMath"), lexeme: "badMath", line: 3, column: 5 }
   11: Token { token_type: LeftParen, lexeme: "(", line: 3, column: 12 }
   12: Token { token_type: IntType, lexeme: "int", line: 3, column: 13 }
   13: Token { token_type: Identifier("a"), lexeme: "a", line: 3, column: 17 }
   14: Token { token_type: Comma, lexeme: ",", line: 3, column: 18 }
   15: Token { token_type: FloatType, lexeme: "float", line: 3, column: 20 }
   16: Token { token_type: Identifier("b"), lexeme: "b", line: 3, column: 26 }
   17: Token { token_type: RightParen, lexeme: ")", line: 3, column: 27 }
   18: Token { token_type: Arrow, lexeme: "->", line: 3, column: 29 }
   19: Token { token_type: IntType, lexeme: "int", line: 3, column: 32 }
   20: Token { token_type: LeftBrace, lexeme: "{", line: 3, column: 36 }
   21: Token { token_type: Newline, lexeme: "\n", line: 3, column: 38 }
   22: Token { token_type: BooleanType, lexeme: "boolean", line: 4, column: 4 }
   23: Token { token_type: Identifier("result"), lexeme: "result", line: 4, column: 12 }
   24: Token { token_type: Assign, lexeme: "=", line: 4, column: 19 }
   25: Token { token_type: Identifier("a"), lexeme: "a", line: 4, column: 21 }
   26: Token { token_type: Plus, lexeme: "+", line: 4, column: 23 }
   27: Token { token_type: Identifier("b"), lexeme: "b", line: 4, column: 25 }
   28: Token { token_type: Semicolon, lexeme: ";", line: 4, column: 26 }
   29: Token { token_type: Newline, lexeme: "\n", line: 4, column: 76 }
   30: Token { token_type: Newline, lexeme: "\n", line: 5, column: 5 }
   31: Token { token_type: If, lexeme: "if", line: 6, column: 4 }
   32: Token { token_type: LeftParen, lexeme: "(", line: 6, column: 7 }
   33: Token { token_type: Identifier("a"), lexeme: "a", line: 6, column: 8 }
   34: Token { token_type: Plus, lexeme: "+", line: 6, column: 10 }
   35: Token { token_type: Identifier("b"), lexeme: "b", line: 6, column: 12 }
   36: Token { token_type: RightParen, lexeme: ")", line: 6, column: 13 }
   37: Token { token_type: LeftBrace, lexeme: "{", line: 6, column: 15 }
   38: Token { token_type: Newline, lexeme: "\n", line: 6, column: 56 }
   39: Token { token_type: Return, lexeme: "return", line: 7, column: 8 }
   40: Token { token_type: StringLiteral("error"), lexeme: "\"error\"", line: 7, column: 15 }
   41: Token { token_type: Semicolon, lexeme: ";", line: 7, column: 22 }
   42: Token { token_type: Newline, lexeme: "\n", line: 7, column: 69 }
   43: Token { token_type: RightBrace, lexeme: "}", line: 8, column: 4 }
   44: Token { token_type: Newline, lexeme: "\n", line: 8, column: 6 }
   45: Token { token_type: Newline, lexeme: "\n", line: 9, column: 5 }
   46: Token { token_type: Return, lexeme: "return", line: 10, column: 4 }
   47: Token { token_type: Identifier("a"), lexeme: "a", line: 10, column: 11 }
   48: Token { token_type: Divide, lexeme: "/", line: 10, column: 13 }
   49: Token { token_type: FloatLiteral(0.0), lexeme: "0.0", line: 10, column: 15 }
   50: Token { token_type: Semicolon, lexeme: ";", line: 10, column: 18 }
   51: Token { token_type: Newline, lexeme: "\n", line: 10, column: 59 }
   52: Token { token_type: RightBrace, lexeme: "}", line: 11, column: 0 }
   53: Token { token_type: Newline, lexeme: "\n", line: 11, column: 2 }
   54: Token { token_type: Newline, lexeme: "\n", line: 12, column: 1 }
   55: Token { token_type: Func, lexeme: "func", line: 13, column: 0 }
   56: Token { token_type: Identifier("arrayError"), lexeme: "arrayError", line: 13, column: 5 }
   57: Token { token_type: LeftParen, lexeme: "(", line: 13, column: 15 }
   58: Token { token_type: RightParen, lexeme: ")", line: 13, column: 16 }
   59: Token { token_type: Arrow, lexeme: "->", line: 13, column: 18 }
   60: Token { token_type: VoidType, lexeme: "void", line: 13, column: 21 }
   61: Token { token_type: LeftBrace, lexeme: "{", line: 13, column: 26 }
   62: Token { token_type: Newline, lexeme: "\n", line: 13, column: 28 }
   63: Token { token_type: IntType, lexeme: "int", line: 14, column: 4 }
   64: Token { token_type: LeftBracket, lexeme: "[", line: 14, column: 7 }
   65: Token { token_type: RightBracket, lexeme: "]", line: 14, column: 8 }
   66: Token { token_type: Identifier("numbers"), lexeme: "numbers", line: 14, column: 10 }
   67: Token { token_type: Assign, lexeme: "=", line: 14, column: 18 }
   68: Token { token_type: LeftBrace, lexeme: "{", line: 14, column: 20 }
   69: Token { token_type: IntLiteral(1), lexeme: "1", line: 14, column: 21 }
   70: Token { token_type: Comma, lexeme: ",", line: 14, column: 22 }
   71: Token { token_type: IntLiteral(2), lexeme: "2", line: 14, column: 24 }
   72: Token { token_type: Comma, lexeme: ",", line: 14, column: 25 }
   73: Token { token_type: StringLiteral("three"), lexeme: "\"three\"", line: 14, column: 27 }
   74: Token { token_type: Comma, lexeme: ",", line: 14, column: 34 }
   75: Token { token_type: IntLiteral(4), lexeme: "4", line: 14, column: 36 }
   76: Token { token_type: RightBrace, lexeme: "}", line: 14, column: 37 }
   77: Token { token_type: Semicolon, lexeme: ";", line: 14, column: 38 }
   78: Token { token_type: Newline, lexeme: "\n", line: 14, column: 71 }
   79: Token { token_type: StringType, lexeme: "string", line: 15, column: 4 }
   80: Token { token_type: LeftBracket, lexeme: "[", line: 15, column: 10 }
   81: Token { token_type: RightBracket, lexeme: "]", line: 15, column: 11 }
   82: Token { token_type: Identifier("words"), lexeme: "words", line: 15, column: 13 }
   83: Token { token_type: Assign, lexeme: "=", line: 15, column: 19 }
   84: Token { token_type: LeftBrace, lexeme: "{", line: 15, column: 21 }
   85: Token { token_type: IntLiteral(1), lexeme: "1", line: 15, column: 22 }
   86: Token { token_type: Comma, lexeme: ",", line: 15, column: 23 }
   87: Token { token_type: IntLiteral(2), lexeme: "2", line: 15, column: 25 }
   88: Token { token_type: Comma, lexeme: ",", line: 15, column: 26 }
   89: Token { token_type: IntLiteral(3), lexeme: "3", line: 15, column: 28 }
   90: Token { token_type: RightBrace, lexeme: "}", line: 15, column: 29 }
   91: Token { token_type: Semicolon, lexeme: ";", line: 15, column: 30 }
   92: Token { token_type: Newline, lexeme: "\n", line: 15, column: 77 }
   93: Token { token_type: Newline, lexeme: "\n", line: 16, column: 5 }
   94: Token { token_type: ForEach, lexeme: "forEach", line: 17, column: 4 }
   95: Token { token_type: LeftParen, lexeme: "(", line: 17, column: 12 }
   96: Token { token_type: StringType, lexeme: "string", line: 17, column: 13 }
   97: Token { token_type: Identifier("word"), lexeme: "word", line: 17, column: 20 }
   98: Token { token_type: In, lexeme: "in", line: 17, column: 25 }
   99: Token { token_type: Identifier("numbers"), lexeme: "numbers", line: 17, column: 28 }
  100: Token { token_type: RightParen, lexeme: ")", line: 17, column: 35 }
  101: Token { token_type: LeftBrace, lexeme: "{", line: 17, column: 37 }
  102: Token { token_type: Newline, lexeme: "\n", line: 17, column: 74 }
  103: Token { token_type: Newline, lexeme: "\n", line: 18, column: 19 }
  104: Token { token_type: RightBrace, lexeme: "}", line: 19, column: 4 }
  105: Token { token_type: Newline, lexeme: "\n", line: 19, column: 6 }
  106: Token { token_type: Newline, lexeme: "\n", line: 20, column: 5 }
  107: Token { token_type: IntType, lexeme: "int", line: 21, column: 4 }
  108: Token { token_type: Identifier("value"), lexeme: "value", line: 21, column: 8 }
  109: Token { token_type: Assign, lexeme: "=", line: 21, column: 14 }
  110: Token { token_type: Identifier("numbers"), lexeme: "numbers", line: 21, column: 16 }
  111: Token { token_type: And, lexeme: "&&", line: 21, column: 24 }
  112: Token { token_type: Identifier("words"), lexeme: "words", line: 21, column: 27 }
  113: Token { token_type: Semicolon, lexeme: ";", line: 21, column: 32 }
  114: Token { token_type: Newline, lexeme: "\n", line: 21, column: 72 }
  115: Token { token_type: RightBrace, lexeme: "}", line: 22, column: 0 }
  116: Token { token_type: Newline, lexeme: "\n", line: 22, column: 2 }
  117: Token { token_type: Newline, lexeme: "\n", line: 23, column: 1 }
  118: Token { token_type: Func, lexeme: "func", line: 24, column: 0 }
  119: Token { token_type: Identifier("main"), lexeme: "main", line: 24, column: 5 }
  120: Token { token_type: LeftParen, lexeme: "(", line: 24, column: 9 }
  121: Token { token_type: RightParen, lexeme: ")", line: 24, column: 10 }
  122: Token { token_type: Arrow, lexeme: "->", line: 24, column: 12 }
  123: Token { token_type: VoidType, lexeme: "void", line: 24, column: 15 }
  124: Token { token_type: LeftBrace, lexeme: "{", line: 24, column: 20 }
  125: Token { token_type: Newline, lexeme: "\n", line: 24, column: 22 }
  126: Token { token_type: IntType, lexeme: "int", line: 25, column: 4 }
  127: Token { token_type: Identifier("x"), lexeme: "x", line: 25, column: 8 }
  128: Token { token_type: Assign, lexeme: "=", line: 25, column: 10 }
  129: Token { token_type: IntLiteral(5), lexeme: "5", line: 25, column: 12 }
  130: Token { token_type: Semicolon, lexeme: ";", line: 25, column: 13 }
  131: Token { token_type: Newline, lexeme: "\n", line: 25, column: 15 }
  132: Token { token_type: FloatType, lexeme: "float", line: 26, column: 4 }
  133: Token { token_type: Identifier("y"), lexeme: "y", line: 26, column: 10 }
  134: Token { token_type: Assign, lexeme: "=", line: 26, column: 12 }
  135: Token { token_type: FloatLiteral(3.14), lexeme: "3.14", line: 26, column: 14 }
  136: Token { token_type: Semicolon, lexeme: ";", line: 26, column: 18 }
  137: Token { token_type: Newline, lexeme: "\n", line: 26, column: 20 }
  138: Token { token_type: Newline, lexeme: "\n", line: 27, column: 5 }
  139: Token { token_type: BooleanType, lexeme: "boolean", line: 28, column: 4 }
  140: Token { token_type: Identifier("flag"), lexeme: "flag", line: 28, column: 12 }
  141: Token { token_type: Assign, lexeme: "=", line: 28, column: 17 }
  142: Token { token_type: Identifier("x"), lexeme: "x", line: 28, column: 19 }
  143: Token { token_type: Greater, lexeme: ">", line: 28, column: 21 }
  144: Token { token_type: Identifier("y"), lexeme: "y", line: 28, column: 23 }
  145: Token { token_type: Semicolon, lexeme: ";", line: 28, column: 24 }
  146: Token { token_type: Newline, lexeme: "\n", line: 28, column: 35 }
  147: Token { token_type: IntType, lexeme: "int", line: 29, column: 4 }
  148: Token { token_type: Identifier("result"), lexeme: "result", line: 29, column: 8 }
  149: Token { token_type: Assign, lexeme: "=", line: 29, column: 15 }
  150: Token { token_type: Identifier("flag"), lexeme: "flag", line: 29, column: 17 }
  151: Token { token_type: Plus, lexeme: "+", line: 29, column: 22 }
  152: Token { token_type: IntLiteral(1), lexeme: "1", line: 29, column: 24 }
  153: Token { token_type: Semicolon, lexeme: ";", line: 29, column: 25 }
  154: Token { token_type: Newline, lexeme: "\n", line: 29, column: 56 }
  155: Token { token_type: Newline, lexeme: "\n", line: 30, column: 5 }
  156: Token { token_type: Identifier("x"), lexeme: "x", line: 31, column: 4 }
  157: Token { token_type: Increment, lexeme: "++", line: 31, column: 5 }
  158: Token { token_type: Semicolon, lexeme: ";", line: 31, column: 7 }
  159: Token { token_type: Newline, lexeme: "\n", line: 31, column: 18 }
  160: Token { token_type: Identifier("y"), lexeme: "y", line: 32, column: 4 }
  161: Token { token_type: Decrement, lexeme: "--", line: 32, column: 5 }
  162: Token { token_type: Semicolon, lexeme: ";", line: 32, column: 7 }
  163: Token { token_type: Newline, lexeme: "\n", line: 32, column: 18 }
  164: Token { token_type: Identifier("flag"), lexeme: "flag", line: 33, column: 4 }
  165: Token { token_type: Increment, lexeme: "++", line: 33, column: 8 }
  166: Token { token_type: Semicolon, lexeme: ";", line: 33, column: 10 }
  167: Token { token_type: Newline, lexeme: "\n", line: 33, column: 43 }
  168: Token { token_type: RightBrace, lexeme: "}", line: 34, column: 0 }
  169: Token { token_type: Eof, lexeme: "", line: 34, column: 1 }

=== PHASE 2: SYNTAX ANALYSIS (PARSING) ===
✅ Parsing successful!
Program structure:
  Functions: 3
  Global variables: 1

=== ABSTRACT SYNTAX TREE (AST) SUMMARY ===
  1. Global variable const string NUMBER (initialized)
  2. Function 'badMath' -> int
     Parameters: 2
       1: int a
       2: float b
     Statements in body: 3
     Statement breakdown:
       Return statements: 2
       If statements: 1
       Variable declarations: 1
  3. Function 'arrayError' -> void
     Parameters: 0
     Statements in body: 4
     Statement breakdown:
       Variable declarations: 3
       ForEach loops: 1
  4. Function 'main' -> void
     Parameters: 0
     Statements in body: 7
     Statement breakdown:
       Variable declarations: 4
       Expression statements: 3

=== PHASE 3: SEMANTIC ANALYSIS & TYPE CHECKING ===
