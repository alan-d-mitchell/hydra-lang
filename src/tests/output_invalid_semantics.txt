=== HYDRA LANGUAGE COMPILER ===
Compiling file: src/tests/invalid_semantics.hydra
File size: 580 bytes

=== PHASE 1: LEXICAL ANALYSIS (TOKENIZING) ===
✅ Tokenization successful!
Tokens found: 80

Debug: All tokens:
    0: Token { token_type: Global, lexeme: "global", line: 1, column: 1 }
    1: Token { token_type: IntType, lexeme: "int", line: 1, column: 8 }
    2: Token { token_type: Identifier("undefinedVar"), lexeme: "undefinedVar", line: 1, column: 12 }
    3: Token { token_type: Assign, lexeme: "=", line: 1, column: 25 }
    4: Token { token_type: Identifier("unknownVariable"), lexeme: "unknownVariable", line: 1, column: 27 }
    5: Token { token_type: Semicolon, lexeme: ";", line: 1, column: 42 }
    6: Token { token_type: Newline, lexeme: "\n", line: 1, column: 82 }
    7: Token { token_type: Newline, lexeme: "\n", line: 2, column: 1 }
    8: Token { token_type: Func, lexeme: "func", line: 3, column: 0 }
    9: Token { token_type: Identifier("testFunction"), lexeme: "testFunction", line: 3, column: 5 }
   10: Token { token_type: LeftParen, lexeme: "(", line: 3, column: 17 }
   11: Token { token_type: RightParen, lexeme: ")", line: 3, column: 18 }
   12: Token { token_type: Arrow, lexeme: "->", line: 3, column: 20 }
   13: Token { token_type: IntType, lexeme: "int", line: 3, column: 23 }
   14: Token { token_type: LeftBrace, lexeme: "{", line: 3, column: 27 }
   15: Token { token_type: Newline, lexeme: "\n", line: 3, column: 29 }
   16: Token { token_type: IntType, lexeme: "int", line: 4, column: 4 }
   17: Token { token_type: Identifier("x"), lexeme: "x", line: 4, column: 8 }
   18: Token { token_type: Assign, lexeme: "=", line: 4, column: 10 }
   19: Token { token_type: IntLiteral(5), lexeme: "5", line: 4, column: 12 }
   20: Token { token_type: Semicolon, lexeme: ";", line: 4, column: 13 }
   21: Token { token_type: Newline, lexeme: "\n", line: 4, column: 15 }
   22: Token { token_type: IntType, lexeme: "int", line: 5, column: 4 }
   23: Token { token_type: Identifier("x"), lexeme: "x", line: 5, column: 8 }
   24: Token { token_type: Assign, lexeme: "=", line: 5, column: 10 }
   25: Token { token_type: IntLiteral(10), lexeme: "10", line: 5, column: 12 }
   26: Token { token_type: Semicolon, lexeme: ";", line: 5, column: 14 }
   27: Token { token_type: Newline, lexeme: "\n", line: 5, column: 59 }
   28: Token { token_type: Newline, lexeme: "\n", line: 6, column: 5 }
   29: Token { token_type: Return, lexeme: "return", line: 7, column: 4 }
   30: Token { token_type: Identifier("y"), lexeme: "y", line: 7, column: 11 }
   31: Token { token_type: Semicolon, lexeme: ";", line: 7, column: 12 }
   32: Token { token_type: Newline, lexeme: "\n", line: 7, column: 38 }
   33: Token { token_type: RightBrace, lexeme: "}", line: 8, column: 0 }
   34: Token { token_type: Newline, lexeme: "\n", line: 8, column: 2 }
   35: Token { token_type: Newline, lexeme: "\n", line: 9, column: 1 }
   36: Token { token_type: Func, lexeme: "func", line: 10, column: 0 }
   37: Token { token_type: Identifier("anotherFunction"), lexeme: "anotherFunction", line: 10, column: 5 }
   38: Token { token_type: LeftParen, lexeme: "(", line: 10, column: 20 }
   39: Token { token_type: RightParen, lexeme: ")", line: 10, column: 21 }
   40: Token { token_type: Arrow, lexeme: "->", line: 10, column: 23 }
   41: Token { token_type: VoidType, lexeme: "void", line: 10, column: 26 }
   42: Token { token_type: LeftBrace, lexeme: "{", line: 10, column: 31 }
   43: Token { token_type: Newline, lexeme: "\n", line: 10, column: 33 }
   44: Token { token_type: Return, lexeme: "return", line: 11, column: 4 }
   45: Token { token_type: IntLiteral(42), lexeme: "42", line: 11, column: 11 }
   46: Token { token_type: Semicolon, lexeme: ";", line: 11, column: 13 }
   47: Token { token_type: Newline, lexeme: "\n", line: 11, column: 59 }
   48: Token { token_type: RightBrace, lexeme: "}", line: 12, column: 0 }
   49: Token { token_type: Newline, lexeme: "\n", line: 12, column: 2 }
   50: Token { token_type: Newline, lexeme: "\n", line: 13, column: 1 }
   51: Token { token_type: Func, lexeme: "func", line: 14, column: 0 }
   52: Token { token_type: Identifier("main"), lexeme: "main", line: 14, column: 5 }
   53: Token { token_type: LeftParen, lexeme: "(", line: 14, column: 9 }
   54: Token { token_type: RightParen, lexeme: ")", line: 14, column: 10 }
   55: Token { token_type: Arrow, lexeme: "->", line: 14, column: 12 }
   56: Token { token_type: VoidType, lexeme: "void", line: 14, column: 15 }
   57: Token { token_type: LeftBrace, lexeme: "{", line: 14, column: 20 }
   58: Token { token_type: Newline, lexeme: "\n", line: 14, column: 22 }
   59: Token { token_type: Identifier("undefinedFunction"), lexeme: "undefinedFunction", line: 15, column: 4 }
   60: Token { token_type: LeftParen, lexeme: "(", line: 15, column: 21 }
   61: Token { token_type: RightParen, lexeme: ")", line: 15, column: 22 }
   62: Token { token_type: Semicolon, lexeme: ";", line: 15, column: 23 }
   63: Token { token_type: Newline, lexeme: "\n", line: 15, column: 56 }
   64: Token { token_type: Newline, lexeme: "\n", line: 16, column: 5 }
   65: Token { token_type: Break, lexeme: "break", line: 17, column: 4 }
   66: Token { token_type: Semicolon, lexeme: ";", line: 17, column: 9 }
   67: Token { token_type: Newline, lexeme: "\n", line: 17, column: 43 }
   68: Token { token_type: Skip, lexeme: "skip", line: 18, column: 4 }
   69: Token { token_type: Semicolon, lexeme: ";", line: 18, column: 8 }
   70: Token { token_type: Newline, lexeme: "\n", line: 18, column: 42 }
   71: Token { token_type: Newline, lexeme: "\n", line: 19, column: 5 }
   72: Token { token_type: Identifier("testFunction"), lexeme: "testFunction", line: 20, column: 4 }
   73: Token { token_type: LeftParen, lexeme: "(", line: 20, column: 16 }
   74: Token { token_type: IntLiteral(5), lexeme: "5", line: 20, column: 17 }
   75: Token { token_type: RightParen, lexeme: ")", line: 20, column: 18 }
   76: Token { token_type: Semicolon, lexeme: ";", line: 20, column: 19 }
   77: Token { token_type: Newline, lexeme: "\n", line: 20, column: 60 }
   78: Token { token_type: RightBrace, lexeme: "}", line: 21, column: 0 }
   79: Token { token_type: Eof, lexeme: "", line: 21, column: 1 }

=== PHASE 2: SYNTAX ANALYSIS (PARSING) ===
✅ Parsing successful!
Program structure:
  Functions: 3
  Global variables: 1

=== ABSTRACT SYNTAX TREE (AST) SUMMARY ===
  1. Global variable int undefinedVar (initialized)
  2. Function 'testFunction' -> int
     Parameters: 0
     Statements in body: 3
     Statement breakdown:
       Variable declarations: 2
       Return statements: 1
  3. Function 'anotherFunction' -> void
     Parameters: 0
     Statements in body: 1
     Statement breakdown:
       Return statements: 1
  4. Function 'main' -> void
     Parameters: 0
     Statements in body: 4
     Statement breakdown:
       Skip statements: 1
       Expression statements: 2
       Break statements: 1

=== PHASE 3: SEMANTIC ANALYSIS & TYPE CHECKING ===
